{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train_and_eval_notebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "IGwwxJ255V5M"
      },
      "source": [
        "# Summarisation notebook\n",
        "\n",
        "This is the notebook for summarisation\n",
        "\n",
        "(More descriptions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnnQWNi-5V5U"
      },
      "source": [
        "### 1. Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqditXaE5V5V"
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TestTubeLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from src.summarisation_lightning_model import LmForSummarisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgNeGHZZ5V5X"
      },
      "source": [
        "### 2. Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q97ixQrl5V5Y"
      },
      "source": [
        "args ={\n",
        "    'max_input_len': 512,  # Maximum number of tokens in the source documents, 512 for BART-base, 8192 for LED-base\n",
        "    'max_output_len': 256,  # Maximum number of tokens in the summary\n",
        "    'save_dir': '../models/summarisation_bart',  # Path to save the model and logs, 'models/summarisation_bart' for BART, 'models/summarisation_led' for LED\n",
        "    'tokenizer': '../pretrained_lms/facebook-bart-base',  # Pretrained tokenizer\n",
        "    'model': '../pretrained_lms/facebook-bart-base',  # Pretrained model (facebook-bart-base for BART, allenai-led-base-16384)\n",
        "    'label_smoothing': 0.0, # Label smoothing (not required)\n",
        "    'epochs': 1,  # Number of epochs during training\n",
        "    'batch_size': 4,  # Batch size (1 for LED, 4 for BART)\n",
        "    'grad_accum': 1,  # Gradient accumulation (4 for LED for effective batch size, 1 for BART to keep consistent)\n",
        "    'lr': 0.00003,  # Training learning rate\n",
        "    'warmup': 1000,  # Number of warmup steps\n",
        "    'gpus': 1,  # Number of gpus. 0 for CPU\n",
        "    'precision': 32,  # Double precision (64), full precision (32) \n",
        "                      # or half precision (16). Can be used on CPU, GPU or TPUs.\n",
        "    'cache_dir': '../datasets/cache/' # Path to dataset cache where dataset is converted\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPQx19VA5V5Z"
      },
      "source": [
        "### 3. Initialize Lightning module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6PFCu-b5V5Z"
      },
      "source": [
        "# Initialize with a seed\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    \n",
        "# dataset size. Needed to compute number of steps for the lr scheduler\n",
        "args['dataset_size'] = 50594. # manually entered\n",
        "\n",
        "# Define PyTorch Lightning model\n",
        "model = LmForSummarisation(args)\n",
        "# Include datasets\n",
        "model.hf_datasets = nlp.load_dataset('multi_news', cache_dir=args['cache_dir'])\n",
        "\n",
        "# Define logger\n",
        "logger = TestTubeLogger(\n",
        "    save_dir=args['save_dir'],\n",
        "    name='training',\n",
        "    version=0  # always use version=0\n",
        ")\n",
        "\n",
        "# Define checkpoint saver\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=os.path.join(args['save_dir'], \"training\", \"checkpoints\"),  # Dir path\n",
        "    save_top_k=1,  # Maximum number of checkpoints to be saved\n",
        "    verbose=True,  # Verbose\n",
        "    monitor='avg_val_loss',  # Checkpointing measurement (BLEU validation)\n",
        "    mode='min',      # Maximize measurement over the validation\n",
        "    period=1         # Save every epoch\n",
        ")\n",
        "\n",
        "print(args)\n",
        "\n",
        "\n",
        "# Define lightning trainer\n",
        "trainer = pl.Trainer(gpus=args['gpus'], distributed_backend='dp' if torch.cuda.is_available() else None,\n",
        "                     track_grad_norm=-1,\n",
        "                     max_epochs=args['epochs'],\n",
        "                     max_steps=None,\n",
        "                     replace_sampler_ddp=False,\n",
        "                     accumulate_grad_batches=args['grad_accum'],\n",
        "                     gradient_clip_val=1.0,  # Max grad_norm\n",
        "                     val_check_interval=1.0,  # Num steps between validation\n",
        "                     num_sanity_val_steps=2,  # Validation steps for sanity check\n",
        "                     check_val_every_n_epoch=1,  # Check validation every N\n",
        "                     logger=logger,\n",
        "                     callbacks=checkpoint_callback,\n",
        "                     progress_bar_refresh_rate=10,  # Progress bar for printing (updates every N)\n",
        "                     precision=args['precision'],\n",
        "                     amp_backend='native', amp_level='O2',\n",
        "                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYOshGw25V5c"
      },
      "source": [
        "#### 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HImZnub5V5d"
      },
      "source": [
        "# Train model\n",
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGBKK0zS5V5e"
      },
      "source": [
        "### 5. Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js2Z4IMP5V5f"
      },
      "source": [
        "# Test model\n",
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecM0JA0y5V5f"
      },
      "source": [
        "### 6. Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzWp78cp5V5g"
      },
      "source": [
        "# Define PyTorch Lightning model\n",
        "model = LmForSummarisation.load_from_checkpoint('../models/<path_to_model>.ckpt')\n",
        "\n",
        "document = '<ADD A DOCUMENT TO SUMMARISE>'\n",
        "summary = model.summarise_example(sentence, args['max_input_len'], args['max_output_len'])\n",
        "summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MwxVVYn5V5h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}