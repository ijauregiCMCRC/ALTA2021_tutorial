{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "IGwwxJ255V5M"
   },
   "source": [
    "# Summarisation Notebook\n",
    "\n",
    "In this notebook, we will be running a comparison between a standard BART model and a Longformer Encoder Decoder model. The idea of this comparison is to show the pros and cons of using a long-document transformer, versus a standard pre-trained language model.\n",
    "\n",
    "To run this notebook, you need to ensure that you have the appropriate virtual environment set up, and have installed the `requirements.txt` file located in `ALTA2021_tutorial/summarisation/`.\n",
    "\n",
    "In case you are unfamiliar with the models, the use of HuggingFace, or PyTorch Lightning, here are links below:\n",
    "\n",
    "* **BART**: https://aclanthology.org/2020.acl-main.703/\n",
    "* **Longformer**: https://arxiv.org/abs/2004.05150\n",
    "\n",
    "* **HuggingFace**: https://huggingface.co/\n",
    "* **PyTorch Lightning**: https://www.pytorchlightning.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnnQWNi-5V5U"
   },
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3943,
     "status": "ok",
     "timestamp": 1634884095358,
     "user": {
      "displayName": "Jacob Parnell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02679095314711798196"
     },
     "user_tz": -660
    },
    "id": "KqditXaE5V5V"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "import random\n",
    "import numpy as np\n",
    "import textwrap  # for inference example\n",
    "from rouge_score import rouge_scorer  # for inference example\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import nlp  # to load dataset\n",
    "\n",
    "from src.summarisation_lightning_model import LmForSummarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgNeGHZZ5V5X"
   },
   "source": [
    "### 2. Define Parameters\n",
    "\n",
    "Here we define a dictionary of arguments which we pass to the Lightning script when loading the model. These will differ depending on the model you use, and the task you are performing.\n",
    "\n",
    "For this tutorial, Longformer is an architecture that is built on top of BART's pre-trained model weights, so model-specific arguments will be very similar.\n",
    "\n",
    "The remainder of the arguments are set by default in the Trainer function in the following section, and are specific to PyTorch Lightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1634884099758,
     "user": {
      "displayName": "Jacob Parnell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02679095314711798196"
     },
     "user_tz": -660
    },
    "id": "Q97ixQrl5V5Y"
   },
   "outputs": [],
   "source": [
    "args ={\n",
    "    'max_input_len': 2048,  # Maximum number of tokens in the source documents, 512 for BART-base, 2048 for LED-base\n",
    "    'max_output_len': 256,  # Maximum number of tokens in the summary\n",
    "    'save_dir': '../models/summarisation_led2',  # Path to save the model and logs, 'models/summarisation_bart' for BART, 'models/summarisation_led' for LED\n",
    "    'tokenizer': 'facebook/bart-base',  # Pretrained tokenizer\n",
    "    'model_path': 'allenai/led-base-16384',  # Pretrained model (facebook/bart-base for BART, allenai/led-base-16384)\n",
    "    'label_smoothing': 0.0, # Label smoothing (not required)\n",
    "    'epochs': 1,  # Number of epochs during training\n",
    "    'batch_size': 1,  # Batch size (1 for LED, 4 for BART)\n",
    "    'grad_accum': 1,  # Gradient accumulation (4 for LED for effective batch size, 1 for BART to keep consistent)\n",
    "    'lr': 0.00003,  # Training learning rate\n",
    "    'warmup': 1000,  # Number of warmup steps\n",
    "    'gpus': 1,  # Number of gpus. 0 for CPU\n",
    "    'precision': 16,  # Double precision (64), full precision (32) \n",
    "                      # or half precision (16). Can be used on CPU, GPU or TPUs.\n",
    "    'cache_dir': '../datasets/cache/', # Path to dataset cache where dataset is converted\n",
    "    'attention_dropout': 0.1,  # default\n",
    "    'adafactor': True,  # use Adafactor optimizer, else Adam\n",
    "    'debug': False,  # debug run\n",
    "    'num_workers': 0,  # number of data loader workers\n",
    "    'grad_ckpt': True,  # gradient checkpointing to save memory\n",
    "    'attention_mode': 'sliding_chunks',  # Longformer attention mode\n",
    "    'attention_window': 512  # Longformer attention window\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPQx19VA5V5Z"
   },
   "source": [
    "### 3. Initialize Lightning Module\n",
    "\n",
    "In this section, we load the model and dataset we choose to use. In this instance, we are loading a dataset that is stored on the HuggingFace Datasets repository. If you have your own dataset you wish to use for training and testing, please review the link <a href=\"https://huggingface.co/docs/datasets/\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 9027,
     "status": "error",
     "timestamp": 1634884111302,
     "user": {
      "displayName": "Jacob Parnell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02679095314711798196"
     },
     "user_tz": -660
    },
    "id": "h6PFCu-b5V5Z",
    "outputId": "15da685c-dbd3-4fc6-cd5f-3be1a9c79845",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEDConfig {\n",
      "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"LEDForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"attention_mode\": \"sliding_chunks\",\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_decoder_position_embeddings\": 1024,\n",
      "  \"max_encoder_position_embeddings\": 16384,\n",
      "  \"model_type\": \"led\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:488: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_epochs` instead.\n",
      "  \"Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5.\"\n",
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:111: LightningDeprecationWarning: `Trainer(distributed_backend=dp)` has been deprecated and will be removed in v1.5. Use `Trainer(accelerator=dp)` instead.\n",
      "  f\"`Trainer(distributed_backend={distributed_backend})` has been deprecated and will be removed in v1.5.\"\n",
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_input_len': 2048, 'max_output_len': 256, 'save_dir': '../models/summarisation_led2', 'tokenizer': 'facebook/bart-base', 'model_path': 'allenai/led-base-16384', 'label_smoothing': 0.0, 'epochs': 1, 'batch_size': 1, 'grad_accum': 1, 'lr': 3e-05, 'warmup': 1000, 'gpus': 1, 'precision': 16, 'cache_dir': '../datasets/cache/', 'attention_dropout': 0.1, 'adafactor': True, 'debug': False, 'num_workers': 0, 'grad_ckpt': True, 'attention_mode': 'sliding_chunks', 'attention_window': 512, 'dataset_size': 50594}\n"
     ]
    }
   ],
   "source": [
    "# Initialize with a seed\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# dataset size. Needed to compute number of steps for the lr scheduler\n",
    "args['dataset_size'] = 50594 # manually entered\n",
    "\n",
    "# Define PyTorch Lightning model\n",
    "model = LmForSummarisation(args)\n",
    "# Include datasets\n",
    "model.hf_datasets = nlp.load_dataset('multi_news', cache_dir=args['cache_dir'])\n",
    "\n",
    "# Define logger\n",
    "logger = TestTubeLogger(\n",
    "    save_dir=args['save_dir'],\n",
    "    name='training',\n",
    "    version=0  # always use version=0\n",
    ")\n",
    "\n",
    "# Define checkpoint saver\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(args['save_dir'], \"training\", \"checkpoints\"),  # Dir path\n",
    "    filename='check-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='validation_loss',\n",
    "    mode='min',\n",
    "    period=1\n",
    ")\n",
    "\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Define lightning trainer\n",
    "trainer = pl.Trainer(gpus=args['gpus'], distributed_backend='dp' if torch.cuda.is_available() else None,\n",
    "                     track_grad_norm=-1,\n",
    "                     max_epochs=args['epochs'],\n",
    "                     max_steps=None,\n",
    "                     replace_sampler_ddp=False,\n",
    "                     accumulate_grad_batches=args['grad_accum'],\n",
    "                     gradient_clip_val=1.0,  # Max grad_norm\n",
    "                     val_check_interval=1.0,  # Num steps between validation\n",
    "                     num_sanity_val_steps=2,  # Validation steps for sanity check\n",
    "                     check_val_every_n_epoch=1,  # Check validation every N\n",
    "                     logger=logger,\n",
    "                     callbacks=checkpoint_callback,\n",
    "                     progress_bar_refresh_rate=10,  # Progress bar for printing (updates every N)\n",
    "                     precision=args['precision'],\n",
    "                     amp_backend='native', amp_level='O2'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYOshGw25V5c"
   },
   "source": [
    "### 4. Train Model\n",
    "\n",
    "In this section and the following, we look to train the BART or Longformer model, and evaluate it over a test set. A few points to note about the comparison between the two models:\n",
    "\n",
    "* Training time will differ significantly - this is due to the amount of information that either model will need to process. Despite linear attention alleviating quadratic memory complexity, and allowing Longformer to fit in memory, processing much more data will take longer to train compared to BART.\n",
    "\n",
    "* We have chosen to showcase a fraction of the power of BART and Longformer, by restricting their input lengths to 512 and 2048 tokens respectively. This is merely to facilitate the training and testing process. It is worth reminding that Longformer can process up to 16x the maximum input length of BART (16384 vs. 1024 tokens).\n",
    "\n",
    "* ROUGE score improvements here are modest, but will increase significantly with longer training times, adequate selection of hyperparameters (e.g. increasing input length, batch size), and the use of the -large variants of these models.\n",
    "\n",
    "* Summarisation is a computationally heavy task, and can often require a GPU with quite large RAM to utilise the full benefits of either model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390,
     "referenced_widgets": [
      "9c6c841f982b462285ae2503d20215ea",
      "24b3509be66b44618158d669a2b45fe3",
      "12645c3cc1574d50be92ff42bee9031e",
      "b0d47eddc9924df2b2be802deec035eb",
      "e895ffb10bae42a2a2884a296b0de756",
      "ed55bc6e0f884f9c9ea034c571ed8488",
      "f998509d191c4e55aa96bd6fdbd0f576",
      "8162357e8e104df2838d1e5b1899bbec",
      "ba520a87665a46f99ed57f9f993ad2b5",
      "03e26d56cd714bfb869f777350c73776",
      "747bda1714a643f9b6cb31ab523c3887",
      "1fb5b1e0b38c40afb50476ee0ae79cf3",
      "6b4dce5f599349f99ab9a917c2b29e3a",
      "6f964a9e67bf40a4ba9c08a66c447e11",
      "e14c3b49f2914777a5f7affb65c08571",
      "edfa3910f40c463ab4bb2c92c1a7a1c9",
      "4b8f7c42658042fa8e4933491c0e4114",
      "4ec033a2c2134231abfd7a07f126d071",
      "1e2aa15892224f4fa53b8f4686d1526f",
      "36e2d16e412046e590e53fe2ee0b15d1",
      "3f331cc3bfba4205ad8ee1a0371817f7",
      "9034b1352a314bf1899d3ce712a27b51"
     ]
    },
    "executionInfo": {
     "elapsed": 102831,
     "status": "ok",
     "timestamp": 1634884059440,
     "user": {
      "displayName": "Jacob Parnell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02679095314711798196"
     },
     "user_tz": -660
    },
    "id": "7HImZnub5V5d",
    "outputId": "d49573c7-c4da-443d-db0f-27bed8453b08",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                        | Params\n",
      "------------------------------------------------------\n",
      "0 | model | LEDForConditionalGeneration | 161 M \n",
      "------------------------------------------------------\n",
      "161 M     Trainable params\n",
      "0         Non-trainable params\n",
      "161 M     Total params\n",
      "647.378   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7416ee8e18a94a27be51bdf6d971fd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n",
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vloss': tensor(4.4006, device='cuda:0'), 'rouge1': tensor(0.0628, device='cuda:0'), 'rouge2': tensor(0., device='cuda:0'), 'rougeL': tensor(0.0528, device='cuda:0'), 'rougeLsum': tensor(0.0528, device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a569a5af3c43ecbb8400f4a63e8699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:406: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n",
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:141: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(parameters, clip_val)\n",
      "/data/jsparnel/py36_alta/lib64/python3.6/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15281419fec141beb3dc00e105c1c514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGBKK0zS5V5e"
   },
   "source": [
    "### 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Js2Z4IMP5V5f"
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecM0JA0y5V5f"
   },
   "source": [
    "### 6. Inference\n",
    "\n",
    "In this final section, we will load the trained model from the its saved directory and use it purely for inference. We can compare empirically the benefit of using a long-document Transformer such as Longformer for document summarisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1634881474310,
     "user": {
      "displayName": "Jacob Parnell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02679095314711798196"
     },
     "user_tz": -660
    },
    "id": "QzWp78cp5V5g",
    "outputId": "bae3097b-8bc0-4dbf-f0e6-86e1a9c2f36d",
    "scrolled": false
   },
   "source": [
    "#### Document Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from Multi-News (3 documents separated by |||||)\n",
    "document = 'If True, Building Set For Demolition Could Be Manhattan\\'s Oldest October 15, 2013 5:39 PM      Preservationist Adam Woodward discovered a cellar that he believes could be the foundation of the Revolutionary War-era Bull’s Head Tavern. (credit: Adam Woodward)      NEW YORK (CBSNewYork) — A preservationist says he has found evidence that a Manhattan building is the former site of an 18th-century tavern where George Washington is believed to have enjoyed a celebratory drink during the American Revolution.      If it is indeed the home of the legendary watering hole, the discovery could mean that the building that is perhaps Manhattan’s oldest is slated to demolished.      “After the English had marched up the Bowery and out of the city (in 1783), George Washington and Governor (George) Clinton stopped at the Bull’s Head (tavern),” preservationist Adam Woodward told WCBS 880’s Alex Silverman.      play pause Preservationist Believes He\\'s Found Tavern Where George Washington Visited      WCBS 880\\'s Alex Silverman...                  The building at 50 Bowery, which has had many faces since, is being prepared for demolition so a hotel can be built at the site. Legend had it that “the Bull’s Head’s structure, cellar, bones” were still inside, Woodward said.      He decided to poke around and, in the basement, Woodward found what he believes are Colonial-era, hand-hewn and hand-planed joists and foundation walls.      “Found myself in what I am pretty certain is the 1750s historic tavern,” he said.      Woodward said he felt compelled to investigate in the building, which once housed a chain drugstore and the Atlantic Garden beer garden, because time was running out.      “I just realized that it would be the last chance to solve one of the great mysteries of New York City history,” he said.      “It was pretty incredible walking back in time 250 years.”      Historian and author David Freeland told Silverman that the find “would make it very likely the oldest building remaining in Manhattan.”      That has Woodward hoping city officials will act quickly to preserve the site.      “What an incredible opportunity that the city suddenly has for this thing to re-emerge,” he said.      You May Also Be Interested In These Stories ||||| Photo      Maybe George Washington slept there, or maybe he only watered his horse and ordered stronger stuff for himself. Either way, David Freeland sounded excited as he crossed the threshold where a famous Colonial-era tavern, the Bull’s Head, once welcomed thirsty out-of-towners.      “There are treasures inside,” said Mr. Freeland, an author and a historian who researched the site for a book about a beer garden that later occupied the tavern’s place on the Bowery.      Photo      But all he saw was debris from the building’s most recent life, as a chain drugstore with a Chinese restaurant upstairs. He did not reach the treasures that thrilled local-history aficionados over the weekend — namely, some old-looking joists and foundation walls in the basement — because the steps were blocked by rubble. The site is to be cleared for a hotel.      The joists were discovered by a photographer and preservationist, Adam Woodward, who suspects that structural elements of the Colonial-era tavern were used in the construction of the much larger beer hall, the Atlantic Garden. It reigned as “one of the show places of New York” from 1858 on, The New York Times said when it finally shut down in 1911.      But what about the tavern where Washington established his temporary headquarters in November 1783 as the British withdrew?      “The whole issue of whether the Bull’s Head was buried inside the Atlantic Garden was one of the great mysteries of New York,” Mr. Woodward said.      Until, apparently, the other day, when he got a look inside. He saw iron work from the 19th century and I-beams from later on. And then he saw a stairway to the basement, and headed down.      “At one point there was a distinct change in the building material, from cinder block to a brick-and-stone foundation wall,” he said. “I followed that wall and found myself at the front of the building, under the sidewalk at the Bowery, and looked up and saw what looked to me like 18th-century hand-hewn and hand-planed joists and beams with extremely wide floorboards right above them.”      He said, “I was thinking, I am standing in the cellar of the Bull’s Head.”      The Bull’s Head opened around 1750 on the fringe of what was a still-young city concentrated below the Bowery. Washington and his troops marched down the Bowery and stopped there in 1783 before making “their official entrance into the city proper,” said Kerri Culhane, a historian who wrote the application that won the Bowery a place on the National Register of Historic Places.      The neighborhood “was a butchers’ district in the 18th century and the 19th century,” Ms. Culhane said. “People drove livestock down from the hinterland and the slaughterhouse was behind the Bowery. That’s where the trading took place.”      It was also a home to the ancestors of future V.I.P.’s. “The Astors started out as butchers,” she said, but began snapping up land. They even owned the Bull’s Head site.      But the tavern closed. Mr. Freeland wrote that the building became a store that sold stoves until the Atlantic Garden opened as a beer garden.      It was a popular gathering place for German immigrants in its early days, and in the 1870s and 1880s, the Atlantic Garden was raided repeatedly for selling beer on Sundays, when the city’s excise laws appeared to forbid that. Mr. Freeland noted that the laws did not mention beer, only “intoxicating liquors or wines.” The Atlantic Garden’s owner got off after one raid because the judge sampled the beer the police had seized and complained it was so watered down that “a man might drink by the gallon without getting drunk.”      Later still, the Atlantic Garden became “a place where Tin Pan Alley songwriters would go to plug their songs,” Mr. Freeland said. One tune that apparently got its start there in the 1890s was “Daisy Bell,” the song that turned the phrase “bicycle built for two” into a catchphrase.      Mr. Woodward said he hoped the demolition for the hotel could be delayed long enough for “a proper archaeological exploration.” (Calls to the owner were not returned on Monday.)      “I can’t think of another lot in Manhattan that has a more important history,” Mr. Woodward said, “and the fact that it might be intact, a couple of feet under the building, is an incredible opportunity to get on archaeological record.”             ||||| Elected officials and the Landmarks Preservation Commission are both doing their best to launch a thorough investigation of what may very well be the famed 18th century saloon the Bull\\'s Head Tavern, but their options are limited. Photographer Adam Woodward first documented the ancient, hand-planed wood joists and stone foundation in the basement of 50 Bowery last week, and both he and historian David Freeland are convinced that these are the remnants of Bull\\'s Head. If so, this would be the oldest surviving structure in Manhattan by far, and as Woodward puts it, an \"incredible opportunity to get on archaeological record.\" But the fate of the site depends on the current owner, Alex Chu, who is demolishing the site to make way for a new hotel.      The Landmarks Commission tells The Lo-Down that they\\'re \"aware of the situation,\" but \"cannot require the owner to conduct archaeology.\" The best they can do is give the owner a list of good archaeologists. Some elected officials are also getting involved, but again they\\'ve got to take it up with Chu first.      · Landmarks Commission: No Jurisdiction to Mandate Historic Site Survey at 50 Bowery [TLD]      · All Coverage of Bull\\'s Head Tavern [~ENY~] |||||'\n",
    "ground_truth = '– In 1783, after the British soldiers left New York City, George Washington is believed to have stopped for a celebratory drink at the Bull\\'s Head tavern. Now a preservationist thinks he\\'s found the historic site—and if he\\'s right, it could be the oldest building in Manhattan. Adam Woodward had heard that the building at 50 Bowery, currently scheduled to be demolished so a hotel can go up, might have \"the Bull\\'s Head\\'s structure, cellar, bones,\" he tells CBS New York. So he searched the basement, and \"found myself in what I am pretty certain is the 1750s historic tavern,\" he says. Specifically, he found what he thinks are hand-hewn and hand-planed joists and foundation walls from the Colonial era. Since that time, the building has housed a drugstore, a Chinese restaurant, and a beer garden, among other things. Now he\\'s hoping city officials will preserve the site, saying, \"What an incredible opportunity that the city suddenly has for this thing to re-emerge.\" A historian is also convinced it is indeed the old tavern, and investigations have been launched by elected officials and the Landmarks Preservation Commission, Eater NY reports. But ultimately, the commission says,'\n",
    "print(textwrap.fill(ground_truth, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../models/summarisation_bart/training/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch Lightning model\n",
    "bart_model = LmForSummarisation.load_from_checkpoint('../models/summarisation_bart/training/checkpoints/check-epoch00.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14225,
     "status": "ok",
     "timestamp": 1634881490536,
     "user": {
      "displayName": "Jacob Parnell",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02679095314711798196"
     },
     "user_tz": -660
    },
    "id": "3MwxVVYn5V5h",
    "outputId": "4811c107-1998-4247-f3fc-feb70a15d16b"
   },
   "outputs": [],
   "source": [
    "bart_summary = bart_model.summarise_example(document)\n",
    "print(textwrap.fill(bart_summary[0], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE score\n",
    "scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=False)\n",
    "score = scorer.score(ground_truth, bart_summary[0])\n",
    "\n",
    "print(f'ROUGE-1: {score['rouge1'.fmeasure]}')\n",
    "print(f'ROUGE-2: {score['rouge2'.fmeasure]}')\n",
    "print(f'ROUGE-L: {score['rougeL'.fmeasure]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Longformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../models/summarisation_bart/training/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch Lightning model\n",
    "led_model = LmForSummarisation.load_from_checkpoint('../models/summarisation_led/training/checkpoints/check-epoch00.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led_summary = model.summarise_example(document)\n",
    "print(textwrap.fill(led_summary[0], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE score\n",
    "scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=False)\n",
    "score = scorer.score(ground_truth, led_summary[0])\n",
    "\n",
    "print(f'ROUGE-1: {score['rouge1'.fmeasure]}')\n",
    "print(f'ROUGE-2: {score['rouge2'.fmeasure]}')\n",
    "print(f'ROUGE-L: {score['rougeL'.fmeasure]}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_and_eval_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03e26d56cd714bfb869f777350c73776": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12645c3cc1574d50be92ff42bee9031e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f998509d191c4e55aa96bd6fdbd0f576",
      "placeholder": "​",
      "style": "IPY_MODEL_ed55bc6e0f884f9c9ea034c571ed8488",
      "value": "Validation sanity check:   0%"
     }
    },
    "1e2aa15892224f4fa53b8f4686d1526f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1fb5b1e0b38c40afb50476ee0ae79cf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f964a9e67bf40a4ba9c08a66c447e11",
       "IPY_MODEL_e14c3b49f2914777a5f7affb65c08571",
       "IPY_MODEL_edfa3910f40c463ab4bb2c92c1a7a1c9"
      ],
      "layout": "IPY_MODEL_6b4dce5f599349f99ab9a917c2b29e3a"
     }
    },
    "24b3509be66b44618158d669a2b45fe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "36e2d16e412046e590e53fe2ee0b15d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f331cc3bfba4205ad8ee1a0371817f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b8f7c42658042fa8e4933491c0e4114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ec033a2c2134231abfd7a07f126d071": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4dce5f599349f99ab9a917c2b29e3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "6f964a9e67bf40a4ba9c08a66c447e11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ec033a2c2134231abfd7a07f126d071",
      "placeholder": "​",
      "style": "IPY_MODEL_4b8f7c42658042fa8e4933491c0e4114",
      "value": "Epoch 0:   0%"
     }
    },
    "747bda1714a643f9b6cb31ab523c3887": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8162357e8e104df2838d1e5b1899bbec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9034b1352a314bf1899d3ce712a27b51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c6c841f982b462285ae2503d20215ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12645c3cc1574d50be92ff42bee9031e",
       "IPY_MODEL_b0d47eddc9924df2b2be802deec035eb",
       "IPY_MODEL_e895ffb10bae42a2a2884a296b0de756"
      ],
      "layout": "IPY_MODEL_24b3509be66b44618158d669a2b45fe3"
     }
    },
    "b0d47eddc9924df2b2be802deec035eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba520a87665a46f99ed57f9f993ad2b5",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8162357e8e104df2838d1e5b1899bbec",
      "value": 0
     }
    },
    "ba520a87665a46f99ed57f9f993ad2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e14c3b49f2914777a5f7affb65c08571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36e2d16e412046e590e53fe2ee0b15d1",
      "max": 50594,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e2aa15892224f4fa53b8f4686d1526f",
      "value": 90
     }
    },
    "e895ffb10bae42a2a2884a296b0de756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_747bda1714a643f9b6cb31ab523c3887",
      "placeholder": "​",
      "style": "IPY_MODEL_03e26d56cd714bfb869f777350c73776",
      "value": " 0/2 [00:06&lt;?, ?it/s]"
     }
    },
    "ed55bc6e0f884f9c9ea034c571ed8488": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edfa3910f40c463ab4bb2c92c1a7a1c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9034b1352a314bf1899d3ce712a27b51",
      "placeholder": "​",
      "style": "IPY_MODEL_3f331cc3bfba4205ad8ee1a0371817f7",
      "value": " 90/50594 [01:52&lt;17:18:08,  1.23s/it, loss=3.2, v_num=0]"
     }
    },
    "f998509d191c4e55aa96bd6fdbd0f576": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
