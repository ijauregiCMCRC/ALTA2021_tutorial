{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Translation notebook\n",
    "\n",
    "This is the notebook for translation\n",
    "\n",
    "(More descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Only for  Google Colab Execution)\n",
    "\n",
    "If you are running the notebook in Google Colab, run the cell below to download the repository witht he required files to run the models and the requirements file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ijauregiCMCRC/ALTA2021_tutorial.git\n",
    "%cd /ALTA2021_tutorial/translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "os.getcwd()\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# For dataset and pretrained model download\n",
    "import gdown\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.translation_lightning_model import LmForTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models folder\n",
    "!mkdir translation_dataset\n",
    "# Download dataset from google drive\n",
    "dataset_link_drive = 'https://drive.google.com/uc?id=1MxrReEXbJPWa3OobANwfzak5rbs5kyNz'\n",
    "dataset_path = './translation_dataset/IWSLT_2014.zip'\n",
    "gdown.download(dataset_link_drive, dataset_path, quiet=False)\n",
    "!unzip './translation_dataset/IWSLT_2014.zip' -d './translation_dataset/'\n",
    "!rm './translation_dataset/IWSLT_2014.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\n",
    "    'train_data': './translation_dataset/IWSLT_2014/es-en/train',  # Path to training data\n",
    "    'validation_data': './translation_dataset/IWSLT_2014/es-en/dev',  # Path to validation data\n",
    "    'test_data': './translation_dataset/IWSLT_2014/es-en/test',  # Path to test data\n",
    "    'src': 'en',  # Source language prefix\n",
    "    'tgt': 'es',  # Target language prefix\n",
    "    'max_src_len': 170,  # Maximum number of tokens in the source sentence\n",
    "    'max_tgt_len': 170,  # Maximum number of tokens in the target sentence\n",
    "    'save_dir': '../models/iwslt_2014/es-en/sshleifer_tiny-mbart',  # Path to save the model and logs\n",
    "    'tokenizer': 'sshleifer/tiny-mbart',  # Pretrained tokenizer\n",
    "    'model': 'sshleifer/tiny-mbart',  # Pretrained model\n",
    "    'add_adapter': False,  # Include adapter training\n",
    "    'reduction_factor': 1,  # Adapter's reduction factor (>= 1)\n",
    "    'label_smoothing': 0.1, # Label smoothing \n",
    "    'epochs': 1,  # Number of epochs during training\n",
    "    'batch_size': 8,  # Batch size\n",
    "    'grad_accum': 1,  # Gradient accumulation\n",
    "    'lr': 0.000003,  # Training learning rate\n",
    "    'warmup': 500,  # Number of warmup steps\n",
    "    'weight_decay': 0.00003,  # Adam weight decay\n",
    "    'gpus': 1,  # Number of gpus. 0 for CPU\n",
    "    'precision': 32,  # Double precision (64), full precision (32) \n",
    "                      # or half precision (16). Can be used on CPU, GPU or TPUs.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initialize Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with a seed\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# dataset size. Needed to compute number of steps for the lr scheduler\n",
    "args['dataset_size'] = sum(1 for line in open(args['train_data'] + '.' + args['src']))\n",
    "\n",
    "# Define PyTorch Lightning model\n",
    "model = LmForTranslation(args)\n",
    "print(model.hf_datasets)\n",
    "\n",
    "# Define logger\n",
    "logger = TestTubeLogger(\n",
    "    save_dir=args['save_dir'],\n",
    "    name='training',\n",
    "    version=0  # always use version=0\n",
    ")\n",
    "\n",
    "# Define checkpoint saver\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(args['save_dir'], \"training\", \"checkpoints\"),  # Dir path\n",
    "    filename='check-{epoch:02d}-{BLEU:.2f}',  # Filename\n",
    "    save_top_k=1,    # Maximum number of checkpoints to be saved\n",
    "    verbose=True,    # Verbose\n",
    "    monitor='BLEU',  # Checkpointing measurement (BLEU validation)\n",
    "    mode='max',      # Maximize measurement over the validation\n",
    "    period=1         # Save every epoch\n",
    ")\n",
    "\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Define lightning trainer\n",
    "trainer = pl.Trainer(gpus=args['gpus'], distributed_backend='dp' if torch.cuda.is_available() else None,\n",
    "                     track_grad_norm=-1,\n",
    "                     max_epochs=args['epochs'],\n",
    "                     max_steps=None,\n",
    "                     replace_sampler_ddp=False,\n",
    "                     accumulate_grad_batches=args['grad_accum'],\n",
    "                     gradient_clip_val=1.0,\n",
    "                     val_check_interval=1.0,\n",
    "                     num_sanity_val_steps=2,\n",
    "                     check_val_every_n_epoch=1,\n",
    "                     logger=logger,\n",
    "                     callbacks=checkpoint_callback,\n",
    "                     progress_bar_refresh_rate=10,\n",
    "                     precision=args['precision'],\n",
    "                     amp_backend='native', amp_level='O2',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Train model\n",
    "trainer.fit(model)\n",
    "print((time.time() - start_time)/60, ' mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models folder\n",
    "!mkdir models\n",
    "# Download them from google drive\n",
    "# BART_base\n",
    "bart_base_url = 'https://drive.google.com/uc?id=1_VA85J5OOf3PltRqhbVLDuDNBtJ-9vOR'\n",
    "bart_base_out = './models/bart_base.zip'\n",
    "gdown.download(bart_base_url, bart_base_out, quiet=False)\n",
    "!unzip './models/bart_base.zip' -d './models/'\n",
    "!rm './models/bart_base.zip'\n",
    "# BART_base_with_adapter\n",
    "bart_base_with_adapter_url = 'https://drive.google.com/uc?id=1Rojznogzr6cMGmi3wt1BeTaputmf6jv4'\n",
    "bart_base_with_adapter_out = './models/bart_base_with_adapter.zip'\n",
    "gdown.download(bart_base_with_adapter_url, bart_base_with_adapter_out, quiet=False)\n",
    "!unzip './models/bart_base_with_adapter.zip' -d './models/'\n",
    "!rm './models/bart_base_with_adapter.zip'\n",
    "# mBART_large\n",
    "mbart_large_url = 'https://drive.google.com/uc?id=115hpgCILR5FTVD-A972xVR3PdqkT9QZ7'\n",
    "mbart_large_out = './models/mbart_large.zip'\n",
    "gdown.download(mbart_large_url, mbart_large_out, quiet=False)\n",
    "!unzip './models/mbart_large.zip' -d './models/'\n",
    "!rm './models/mbart_large.zip'\n",
    "# mBART_large_with_adapter\n",
    "mbart_large_wa_url = 'https://drive.google.com/uc?id=1tCGSk021m8aMkYEd7tm_j-Hp2fYwY5e_'\n",
    "mbart_large_wa_out = './models/mbart_large_wa.zip'\n",
    "gdown.download(mbart_large_wa_url, mbart_large_wa_out, quiet=False)\n",
    "!unzip './models/mbart_large_wa.zip' -d './models/'\n",
    "!rm './models/mbart_large_wa.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English sentence example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence by Alan Turin\n",
    "sentence = 'Sometimes it is the people no one can imagine anything of who do the things no one can imagine.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model...')\n",
    "model = LmForTranslation.load_from_checkpoint('../models/iwslt_2014/es-en/BART_base/training/checkpoints/'\n",
    "                                              'check-epoch=00-BLEU=32.51.ckpt')\n",
    "tp_bart_base, ntp_bart_base = model.num_parameters()\n",
    "start_time = time.time()\n",
    "test_bleu_bart_base = trainer.test(model)[0]['BLEU']\n",
    "training_time_bart_base = 2972\n",
    "inference_time_bart_base = (time.time() - start_time) / 60\n",
    "translation_example_bart_base = model.translate_example(sentence)\n",
    "print('BART_base:')\n",
    "print('-----------------')\n",
    "print('Trainable parameters: ', tp_bart_base)\n",
    "print('Non-trainable parameters: ', ntp_bart_base)\n",
    "print('Total parameters: ', tp_bart_base + ntp_bart_base)\n",
    "print('-----------------')\n",
    "print('Test BLEU: ', test_bleu_bart_base)\n",
    "print('Training time: ', training_time_bart_base, ' mins')\n",
    "print('Inference time: ', inference_time_bart_base, ' mins')\n",
    "print('Translation example-> ', translation_example_bart_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Loading model...')\n",
    "model = LmForTranslation.load_from_checkpoint('../models/iwslt_2014/es-en/BART_base_with_adapter/training/checkpoints'\n",
    "                                              'check-epoch=00-BLEU=20.97.ckpt')\n",
    "tp_bart_base_plus_adapter, ntp_bart_base_plus_adapter = model.num_parameters()\n",
    "start_time = time.time()\n",
    "test_bleu_bart_base_plus_adapter = trainer.test(model)[0]['BLEU']\n",
    "training_time_bart_base_plus_adapter = 1880\n",
    "inference_time_bart_base_plus_adapter = (time.time() - start_time) / 60\n",
    "translation_example_bart_base_plus_adapter = model.translate_example(sentence)\n",
    "print('BART_base_plus_adapter:')\n",
    "print('-----------------')\n",
    "print('Trainable parameters: ', tp_bart_base_plus_adapter)\n",
    "print('Non-trainable parameters: ', ntp_bart_base_plus_adapter)\n",
    "print('Total parameters: ', tp_bart_base_plus_adapter + ntp_bart_base_plus_adapter)\n",
    "print('-----------------')\n",
    "print('Test BLEU: ', test_bleu_bart_base_plus_adapter)\n",
    "print('Training time: ', training_time_bart_base_plus_adapter, ' mins')\n",
    "print('Inference time: ', inference_time_bart_base_plus_adapter, ' mins')\n",
    "print('Translation example-> ', translation_example_bart_base_plus_adapter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model...')\n",
    "model = LmForTranslation.load_from_checkpoint('../models/iwslt_2014/es-en/mBART_large/training/checkpoints/'\n",
    "                                              'check-epoch=00-BLEU=36.47.ckpt')\n",
    "tp_mbart_large, ntp_mbart_large = model.num_parameters()\n",
    "start_time = time.time()\n",
    "test_bleu_mbart_large = trainer.test(model)[0]['BLEU']\n",
    "training_time_mbart_large = 8923\n",
    "inference_time_mbart_large = (time.time() - start_time) / 60\n",
    "translation_example_mbart_large = model.translate_example(sentence)\n",
    "print('mBART_large:')\n",
    "print('-----------------')\n",
    "print('Trainable parameters: ', tp_mbart_large)\n",
    "print('Non-trainable parameters: ', ntp_mbart_large)\n",
    "print('Total parameters: ', tp_mbart_large + ntp_mbart_large)\n",
    "print('-----------------')\n",
    "print('Test BLEU: ', test_bleu_mbart_large)\n",
    "print('Training time: ', training_time_mbart_large, ' mins')\n",
    "print('Inference time: ', inference_time_mbart_large, ' mins')\n",
    "print('Translation example-> ', translation_example_mbart_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model...')\n",
    "model = LmForTranslation.load_from_checkpoint('../models/iwslt_2014/es-en/mBART_large_plus_adapter/training/'\n",
    "                                              'checkpoints/check-epoch=00-BLEU=34.48.ckpt')\n",
    "tp_mbart_large_plus_adapter, ntp_mbart_large_plus_adapter = model.num_parameters()\n",
    "start_time = time.time()\n",
    "test_bleu_mbart_large_plus_adapter = trainer.test(model)[0]['BLEU']\n",
    "training_time_mbart_large_plus_adapter = 4258\n",
    "inference_time_mbart_large_plus_adapter = (time.time() - start_time) / 60\n",
    "translation_example_mbart_large_plus_adapter = model.translate_example(sentence)\n",
    "print('mBART_large_plus_adapter:')\n",
    "print('-----------------')\n",
    "print('Trainable parameters: ', tp_mbart_large_plus_adapter)\n",
    "print('Non-trainable parameters: ', ntp_mbart_large_plus_adapter)\n",
    "print('Total parameters: ', tp_mbart_large_plus_adapter + ntp_mbart_large_plus_adapter)\n",
    "print('-----------------')\n",
    "print('Test BLEU: ', test_bleu_mbart_large_plus_adapter)\n",
    "print('Training time: ', training_time_mbart_large_plus_adapter, ' mins')\n",
    "print('Inference time: ', inference_time_mbart_large_plus_adapter, ' mins')\n",
    "print('Translation example-> ', translation_example_mbart_large_plus_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = ['BART_base', 'BART_base (wa)', 'mBART_large', 'mBART_large (wa)']\n",
    "colors = ['black', 'red', 'blue', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU Scores\n",
    "plt.bar(x_names,\n",
    "       [test_bleu_bart_base, test_bleu_bart_base_plus_adapter, test_bleu_mbart_large, test_bleu_mbart_large_plus_adapter],\n",
    "       color=colors)\n",
    "plt.ylim((30,36))\n",
    "plt.ylabel('BLEU')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Test set evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time vs inference time\n",
    "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "axs[0].bar(x_names,\n",
    "       [training_time_bart_base, training_time_bart_base_plus_adapter, training_time_mbart_large, training_time_mbart_large_plus_adapter],\n",
    "       color=colors)\n",
    "axs[0].set_ylabel('mins')\n",
    "axs[0].set_xticklabels(rotation = 45)\n",
    "axs[0].set_title('training time')\n",
    "axs[1].bar(x_names,\n",
    "       [inference_time_bart_base, inference_time_bart_base_plus_adapter, inference_time_mbart_large, inference_time_mbart_large_plus_adapter],\n",
    "       color=colors)\n",
    "axs[1].set_ylabel('mins')\n",
    "axs[1].set_xticklabels(rotation = 45)\n",
    "axs[1].set_title('inference time')\n",
    "#plt.ylim((30,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model size\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "axs[0].bar(x_names,\n",
    "       [tp_bart_base, tp_bart_base_plus_adapter, tp_mbart_large, tp_mbart_large_plus_adapter],\n",
    "       color=colors)\n",
    "axs[0].set_ylabel('Million')\n",
    "axs[0].set_xticklabels(rotation = 45)\n",
    "axs[0].set_title('# trainable parameters')\n",
    "axs[1].bar(x_names,\n",
    "       [ntp_bart_base, ntp_bart_base_plus_adapter, ntp_mbart_large, ntp_mbart_large_plus_adapter],\n",
    "       color=colors)\n",
    "axs[1].set_ylabel('Million')\n",
    "axs[1].set_xticklabels(rotation = 45)\n",
    "axs[1].set_title('# non-trainable parameters')\n",
    "axs[2].bar(x_names,\n",
    "       [tp_bart_base + ntp_bart_base, tp_bart_base_plus_adapter + ntp_bart_base_plus_adapter, tp_mbart_large + ntp_mbart_large, tp_mbart_large_plus_adapter + ntp_mbart_large_plus_adapter],\n",
    "       color=colors)\n",
    "axs[2].set_ylabel('Million')\n",
    "axs[2].set_xticklabels(rotation = 45)\n",
    "axs[2].set_title('# total parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare translation examples\n",
    "print('BART_base:')\n",
    "print(' -> ', translation_example_bart_base)\n",
    "print('BART_base_plus_adaptr:')\n",
    "print(' -> ', translation_example_bart_base_plus_adapter)\n",
    "print('mBART_large:')\n",
    "print(' -> ', translation_example_mbart_large)\n",
    "print('mBART_large_plus_adapter:')\n",
    "print(' -> ', translation_example_mbart_large_plus_adapter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}